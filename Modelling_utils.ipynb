{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1596,
     "status": "ok",
     "timestamp": 1732013518977,
     "user": {
      "displayName": "Huiran",
      "userId": "09921545535813529831"
     },
     "user_tz": -60
    },
    "id": "Z0REXkZBiUZc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import datetime\n",
    "import random\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "#Avoiding Type 3 fonts in matplotlib plots\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1732013566368,
     "user": {
      "displayName": "Huiran",
      "userId": "09921545535813529831"
     },
     "user_tz": -60
    },
    "id": "aGsi-6rPiUZe"
   },
   "outputs": [],
   "source": [
    "font = {'size'   : 15}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('lines', linewidth=2.0)\n",
    "matplotlib.rc('lines', markersize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVjMoQ_CiUZg"
   },
   "source": [
    "# Modelling long-distance public trips\n",
    "In this section we present the tools we used to derive the best-fitting amplified power-law process as well as the best-fitting truncated power-law for given emperical data-set\n",
    "\n",
    "The parameters and values of the best-fitting processes are stored in a file. As the modelling procedure contains a parameter search this may take time to execute. For convenience, we also provided the `.pkl` files containing the results we obtained, allowing this section to be skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTH0EWVhiUZh"
   },
   "source": [
    "## Error function\n",
    "\n",
    "In order to determine whether a given CCDF $f$ describes the CCDF $g$ of our emperical data well, we use the following error function.\n",
    "For a series of sample points $S$, it calculates the error as $\\frac{2}{|S|}\\sum_{x_i \\in S} \\dfrac{|f(x_i)-g(x_i)|}{ f(x_i)+g(x_i)}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1732013570286,
     "user": {
      "displayName": "Huiran",
      "userId": "09921545535813529831"
     },
     "user_tz": -60
    },
    "id": "p0LONcYIiUZi"
   },
   "outputs": [],
   "source": [
    "''' Error function\n",
    "Compute the distance between the CCDFs of two given data sets\n",
    "\n",
    "d1,d2: the two input data sets, given as a 1-D list of samples.\n",
    "Out of each input, a CCDF is generated. The CCDFs are then compared\n",
    "according to above error metric.\n",
    "\n",
    "max_d: is the empirical trip length value when the CCDF reaches 10^(-3) in a log-log scale CCDF plot, which the max range used for error calculation\n",
    "num: is the number of sampling points in error calculation\n",
    "\n",
    "return: error value\n",
    "'''\n",
    "\n",
    "def custom_distance(d1,d2,max_d,num):\n",
    "    # Check input types\n",
    "    if not (isinstance(d1, (np.ndarray, list, pd.Series)) and isinstance(d2, (np.ndarray, list, pd.Series))):\n",
    "        raise ValueError('Wrong: Data type is not ndarray, List, or pd.Series')\n",
    "\n",
    "    # Convert lists or pd.Series to numpy arrays for efficient computation\n",
    "    d1 = np.array(d1)\n",
    "    d2 = np.array(d2)\n",
    "\n",
    "    # re-sampling\n",
    "    # given the point x value and whole data, calculate the point of y value in CCDF\n",
    "    sorted_d1 = np.sort(d1)\n",
    "    y_d1=1- np.linspace(0, 1, len(sorted_d1), endpoint=False)\n",
    "\n",
    "    sorted_d2 = np.sort(d2)\n",
    "    y_d2=1- np.linspace(0, 1, len(sorted_d2), endpoint=False)\n",
    "    \n",
    "    # Create interpolation functions for the CCDFs\n",
    "    interp_d1 = interp1d(sorted_d1, y_d1, bounds_error=False,fill_value=0)\n",
    "    interp_d2 = interp1d(sorted_d2, y_d2, bounds_error=False,fill_value=0)\n",
    "\n",
    "    \n",
    "    # Find the overlapping range of the two distributions\n",
    "    min_d = max(np.min(d1), np.min(d2))\n",
    "    \n",
    "    # Linearly spaced points for interpolation\n",
    "    points = np.linspace(min_d, max_d, num)\n",
    "\n",
    "    # Interpolate both distributions at the same points\n",
    "    interp_y_d1 = interp_d1(points)\n",
    "    interp_y_d2 = interp_d2(points)\n",
    "    \n",
    "\n",
    "    # Calculate the relative error in a vectorized way\n",
    "    denom = (interp_y_d1 + interp_y_d2) / 2\n",
    "    sum_error = np.abs(interp_y_d1 - interp_y_d2) / denom \n",
    "    error = np.nanmean(sum_error)\n",
    "    \n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error function-----used for Modelling in the power law with the exponential truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' New Error function-----used for find the power law with the exponential truncation\n",
    "Compute the distance between the CCDFs of two given data sets\n",
    "\n",
    "d1,d2: the two input data sets, given as a 1-D list of samples.\n",
    "Out of each input, a CCDF is generated. The CCDFs are then compared\n",
    "according to above error metric.\n",
    "\n",
    "d1 is kind of CCDF value already(Fd), d2 is the regular 1-D samples\n",
    "Ds is the distribution of points for getting d1, use the same range to get the interpolation value in d2\n",
    "max_d: is the empirical trip length value when the CCDF reaches 10^(-3) in a log-log scale CCDF plot, which the max range used for error calculation\n",
    "num: is the number of sampling points in error calculation\n",
    "\n",
    "return: error value\n",
    "'''\n",
    "\n",
    "def custom_distance_exp(d1,d2,Ds,max_d,num):\n",
    "    # Check input types\n",
    "    if not (isinstance(d1, (np.ndarray, list, pd.Series)) and isinstance(d2, (np.ndarray, list, pd.Series))):\n",
    "        raise ValueError('Wrong: Data type is not ndarray, List, or pd.Series')\n",
    "\n",
    "    # Convert lists or pd.Series to numpy arrays for efficient computation\n",
    "    d1 = np.array(d1)\n",
    "    d2 = np.array(d2)\n",
    "\n",
    "    sorted_d2 = np.sort(d2)\n",
    "    y_d2=1- np.linspace(0, 1, len(sorted_d2), endpoint=False)\n",
    "\n",
    "    # Create interpolation functions for the CCDFs,extended left=1, right=0\n",
    "    interp_d1 = interp1d(Ds, d1, bounds_error=False,fill_value=(1,0)) # Ds is already sorted\n",
    "    interp_d2 = interp1d(sorted_d2, y_d2, bounds_error=False,fill_value=(1,0))\n",
    "\n",
    "    # Find the overlapping range of the two distributions\n",
    "    min_d = max(np.min(Ds), np.min(d2))\n",
    "    \n",
    "    # Sampling method : Linear: # Linearly spaced points for interpolation\n",
    "    points = np.linspace(min_d, max_d, num)\n",
    "\n",
    "    # Interpolate both distributions at the same point\n",
    "    interp_y_d1 = interp_d1(points)\n",
    "    interp_y_d2 = interp_d2(points)\n",
    "\n",
    "\n",
    "    # Calculate the relative error in a vectorized way\n",
    "    denom = (interp_y_d1 + interp_y_d2) / 2\n",
    "    sum_error = np.abs(interp_y_d1 - interp_y_d2) / denom \n",
    "    error = np.nanmean(sum_error)\n",
    "        \n",
    "\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the maximum range of trip length for error cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculate the trip length value (max_d in the error calculation function) when the CCDF reaches 10^(-3) in a log-log scale CCDF plot, \n",
    "    which will be used to determine the maximum range of error\n",
    "\n",
    "d1: a 1-D dataset, like emipircal data in our project \n",
    "y_value: is the exact value in y axis in a log-log scale CCDF plot\n",
    "\n",
    "return: the exact value (as possible) of corresponding x value ----> max_d\n",
    "'''\n",
    "def get_xCCDF(d1, y_value=1e-3):\n",
    "    # cal ccdf\n",
    "    d1 = np.array(d1)\n",
    "    sorted_d1 = np.sort(d1)\n",
    "    y_d1 = 1 - np.linspace(0, 1, len(sorted_d1), endpoint=False)\n",
    "    \n",
    "    # target（log-log scale, 10^-3）\n",
    "    target_y = y_value\n",
    "    \n",
    "    # Find the first position where y_d1 <= target_y (y_d1 is monotonically decreasing)\n",
    "    idx = np.searchsorted(y_d1[::-1], target_y, side='left') # searchsorted need monotonically increasing, so inverse the y_d1\n",
    "    idx = len(y_d1) - idx  # inverse index\n",
    "    \n",
    "    # Extract neighbouring points (make sure y1 > target_y > y2)\n",
    "    x1, x2 = sorted_d1[idx-1], sorted_d1[idx]\n",
    "    y1, y2 = y_d1[idx-1], y_d1[idx]\n",
    "    \n",
    "    # Linear interpolation in log-log space\n",
    "    log_x = np.log10(x1) + (np.log10(target_y) - np.log10(y1)) / (np.log10(y2) - np.log10(y1)) * (np.log10(x2) - np.log10(x1))\n",
    "    x_target = 10 ** log_x\n",
    "    \n",
    "    return x_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAXUTbkHiUZj"
   },
   "source": [
    "## Finding the best-fitting amplified power-law model for a given data-set\n",
    "Here we derive the parameters of the amplified power-law process that best describes the empirical data-set.\n",
    "The values of the best-fitting process are then stored for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2QzuZw7iUZk"
   },
   "source": [
    "### Function of finding optimal parameters of training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1732013575672,
     "user": {
      "displayName": "Huiran",
      "userId": "09921545535813529831"
     },
     "user_tz": -60
    },
    "id": "MSyBQdgUiUZn",
    "outputId": "3f92de15-1258-4a13-a1a1-42b6c243bd4f"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Find the best-fitting parameter values for a distance-amplified power-law process\n",
    "that follows the rules specified in the two previous blocks.\n",
    "\n",
    "Input:\n",
    "    combinable-- an array of all parameter combinations to consider, error is null at the begining\n",
    "    sampleSize: number of samples for finding the optimal parameters\n",
    "    min_distance,max_distance: range of trip length to be considered\n",
    "    maxdistance: used for dynamic method, usually equals to max_distance\n",
    "    max_d: the max range of trip length in error calculation\n",
    "    num: number of sampling points for error calculation\n",
    "Return:\n",
    "    full-filled combinale error\n",
    "'''\n",
    "\n",
    "def find_opt_params(combinable,sampleSize,min_distance,maxdistance,df_vec,max_d,num):\n",
    "    tmp_max=maxdistance/2 # half of the maximum allowed distance for any trip\n",
    "    n_samples = len(combinable)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        # if i%100==0:\n",
    "        #     print(\"Samples completed: \",i)\n",
    "        #     print (\"Current date and time : \",datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        eps, p, alp, error, all_dist = combinable[i]\n",
    "        dist = []\n",
    "       \n",
    "        # simulate each trip\n",
    "        for n in range(sampleSize):\n",
    "            distance=9999999\n",
    "            tmp=np.random.uniform(0,1)\n",
    "            max_distance=np.sqrt(1-tmp)*tmp_max+tmp_max\n",
    "            while(distance>=max_distance or distance<min_distance):\n",
    "\n",
    "                # draw distance from the power-law distribution with parameter alp\n",
    "                # amplification part\n",
    "                #start with drawn power-law distance\n",
    "                distance=np.random.uniform(0,1)**(-1/(alp-1))\n",
    "                #compute how many times an amplifications occurs\n",
    "                number=np.random.geometric(1-p)\n",
    "                #amplify by factor (1+eps) each time\n",
    "                distance=((1+eps)**(number-1))*distance\n",
    "\n",
    "            dist.append(distance)\n",
    "\n",
    "        combinable[i][4]=dist\n",
    "        # error computation\n",
    "        error=custom_distance(dist,df_vec,max_d,num)\n",
    "        combinable[i][3]=error\n",
    "\n",
    "    \n",
    "    return combinable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power law with exponential truncation\n",
    "- $f(d)=C*\\dfrac{1}{d^{\\alpha}} * e^{-\\frac{d}{\\gamma}}$\n",
    "\n",
    "- $\\sum_{d=100}^{900}f(d)=1$\n",
    "\n",
    "$C=\\dfrac{1}{\\sum_{d=100}^{900}\\dfrac{1}{d^{\\alpha}} * e^{-\\frac{d}{\\gamma}}}$\n",
    "\n",
    "- $\\alpha=1.02....1.2$, step=0.01\n",
    "\n",
    "- $\\gamma=200,250,300....600$, step=50\n",
    "\n",
    "- $d=100,150...900....2000$ step=50\n",
    "\n",
    "- $\\sum_{i=d}^{900}f(i)=F(d)$\n",
    "\n",
    "Compute C and plot F(d), f(x) is kind of pdf\n",
    "Known: gamma (interval can be 10 or 50firstly), alpha, d(distance from 100 to 900 )\n",
    "\n",
    "$\\sum_{d=1}^{10^3} 1/d^{1.02} * e^{-d/600}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Density function of the truncated power-law distribution\n",
    "'''\n",
    "def funcD(C,d,alpha,gamma):\n",
    "    fD=C/d**alpha*(math.exp(-d/gamma))\n",
    "    return fD\n",
    "\n",
    "# This function is used as a helper function when computing C\n",
    "def funcD_noC(d,alpha,gamma):\n",
    "    fD_noC=1/d**alpha*(math.exp(-d/gamma))\n",
    "    return fD_noC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finding optimal combination of parameters for power law with exponential truncation\n",
    "'''\n",
    "def get_results_PL_exp(alphas,gammas,Ds,data,max_d,num):\n",
    "    results=[] # results contain alpha, gamma,C, error between the truncated power-law and emiprical data\n",
    "\n",
    "    # for each combination of alpha and gamma\n",
    "    for alpha in alphas:\n",
    "        for gamma in gammas:\n",
    "            # first compute the normalization constant C\n",
    "            temp=0\n",
    "            for d in Ds:\n",
    "                temp+=funcD_noC(d,alpha,gamma)\n",
    "            C=1/temp\n",
    "    \n",
    "            #compute the (approximate) CCDF F(d) of a truncated power-law\n",
    "            #at several sample points given by Ds\n",
    "            Fd=[0]*len(Ds)\n",
    "            for idx,d in enumerate(Ds):\n",
    "                for i in Ds[Ds>=d]:\n",
    "                    Fd[idx]+=funcD(C,i,alpha,gamma)\n",
    "            \n",
    "            empircal_data=data.tolist()\n",
    "            error=custom_distance_exp(Fd,empircal_data,Ds,max_d,num)         \n",
    "            # error=ccdf_sampling_error(df_vec,Ds,Fd)\n",
    "            results.append([alpha,gamma,C,error])\n",
    "\n",
    "    #convert results to dataframe\n",
    "    results_truncated=pd.DataFrame(results, columns =['alpha', 'gamma', 'C','error']) \n",
    "    # save the optimal results\n",
    "    opt_truncated=results_truncated.iloc[results_truncated.error.argmin(),:]\n",
    "\n",
    "    return opt_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
